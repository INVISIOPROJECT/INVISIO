
import requests
from datetime import date, timedelta

API_KEY = "ad36b4e0ebac4c86a8302bea77af8255"
topic = "artificial intelligence"
language = "en"
from_date = (date.today() - timedelta(days=7)).isoformat()  # Ø¢Ø®Ø± 7 Ø£ÙŠØ§Ù…
sources = "bbc-news,cnn,reuters"

url = (
    f"https://newsapi.org/v2/everything?"
    f"q={topic}&"
    f"language={language}&"
    f"from={from_date}&"
    f"sources={sources}&"
    f"sortBy=publishedAt&"
    f"pageSize=20&"
    f"apiKey={API_KEY}"
)

response = requests.get(url)
data = response.json()

if "articles" in data:
    for idx, article in enumerate(data["articles"], 1):
        print(f"ğŸ”¹ {idx}. {article['title']}")
        print(f"   Ø§Ù„Ù…ØµØ¯Ø±: {article['source']['name']}")
        print(f"   Ø§Ù„ØªØ§Ø±ÙŠØ®: {article['publishedAt']}")
        print(f"   Ø§Ù„ÙˆØµÙ: {article.get('description', 'Ù„Ø§ ÙŠÙˆØ¬Ø¯')}")
        print()
else:
    print("Ø­Ø¯Ø« Ø®Ø·Ø£:", data.get("message", "Ù…Ø´ÙƒÙ„Ø© ØºÙŠØ± Ù…Ø¹Ø±ÙˆÙØ©"))

import nltk
import re
from nltk.corpus import stopwords
from nltk.stem import WordNetLemmatizer

nltk.download('punkt_tab')
nltk.download('stopwords')
nltk.download('wordnet')

stop_words = set(stopwords.words('english'))
lemmatizer = WordNetLemmatizer()

def preprocess(text):
    text = text.lower()
    text = re.sub(r'[^a-zA-Z\s]', '', text)  # Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ø±Ù…ÙˆØ²
    tokens = nltk.word_tokenize(text)
    tokens = [word for word in tokens if word not in stop_words]
    tokens = [lemmatizer.lemmatize(word) for word in tokens]
    return tokens

processed_texts = [preprocess(text) for text in texts]
print(processed_texts[0])

from gensim import corpora

# Ø¥Ù†Ø´Ø§Ø¡ Ù‚Ø§Ù…ÙˆØ³ Ù…Ù† Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„ÙØ±ÙŠØ¯Ø©
dictionary = corpora.Dictionary(processed_texts)

# ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ù†ØµÙˆØµ Ø¥Ù„Ù‰ ØªÙ…Ø«ÙŠÙ„ Ø±Ù‚Ù…ÙŠ (Bag-of-Words)
corpus = [dictionary.doc2bow(text) for text in processed_texts]

!pip install gensim

from gensim.models import CoherenceModel

coherence_model = CoherenceModel(model=lda_model, texts=processed_texts, dictionary=dictionary, coherence='c_v')
score = coherence_model.get_coherence()
print(f"Coherence Score: {score}")

import pyLDAvis
import pyLDAvis.gensim_models

pyLDAvis.enable_notebook()  # Ù„Ø¬ÙˆØ¨ØªØ± Ù†ÙˆØªØ¨ÙˆÙƒ
vis = pyLDAvis.gensim_models.prepare(lda_model, corpus, dictionary)
pyLDAvis.display(vis)  # ØªÙØªØ­ Ù†Ø§ÙØ°Ø© ØªÙØ§Ø¹Ù„ÙŠØ© Ø¨Ø§Ù„Ù…ØªØµÙØ­



